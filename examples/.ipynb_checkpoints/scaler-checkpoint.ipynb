{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exporting scalers\n",
    "\n",
    "This file contains examples of exporting scalers from `sklearn.preprocessing` library.\n",
    "\n",
    "### Loading common packages\n",
    "Instaling the `sklearn-export` using pip."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install sklearn_export"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading common packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-20T17:27:04.984985Z",
     "start_time": "2021-04-20T17:27:04.735133Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn_export import Export"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exporting StandardScaler\n",
    "\n",
    "The StandardScaler is one of the most common techniques to normalize data. It normalizes data to have zero mean and unit variance. In sklearn it is in the package `sklearn.preprocessing`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-20T17:27:05.325607Z",
     "start_time": "2021-04-20T17:27:05.318601Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us normalize the features of the iris dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-20T17:27:05.759472Z",
     "start_time": "2021-04-20T17:27:05.733279Z"
    }
   },
   "outputs": [],
   "source": [
    "# Loading iris dataset\n",
    "dataset = load_iris()\n",
    "X = dataset['data']\n",
    "\n",
    "# Normalizing features\n",
    "scaler = StandardScaler()\n",
    "Xz = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us save the scaler parameters using `sklearn-export`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-20T17:27:06.135440Z",
     "start_time": "2021-04-20T17:27:06.123251Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'scaler': 'ZscoreScaler',\n",
       " 'mean': [5.843333333333335,\n",
       "  3.057333333333334,\n",
       "  3.7580000000000027,\n",
       "  1.199333333333334],\n",
       " 'std': [0.8253012917851409,\n",
       "  0.43441096773549437,\n",
       "  1.7594040657753032,\n",
       "  0.7596926279021594]}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A new instance of the class Export\n",
    "export = Export(scaler)\n",
    "\n",
    "# Exporting the result in JSON and returning a dict of the JSON objects\n",
    "result = export.to_json(filename='standard_scaler.json')\n",
    "\n",
    "# Taking a look in the dict of the JSON file\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is easy to load the file and have the model data in an dict again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-20T17:27:06.498879Z",
     "start_time": "2021-04-20T17:27:06.491271Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean': [5.843333333333335,\n",
       "  3.057333333333334,\n",
       "  3.7580000000000027,\n",
       "  1.199333333333334],\n",
       " 'scaler': 'ZscoreScaler',\n",
       " 'std': [0.8253012917851409,\n",
       "  0.43441096773549437,\n",
       "  1.7594040657753032,\n",
       "  0.7596926279021594]}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Opening JSON file\n",
    "f = open('standard_scaler.json')\n",
    "\n",
    "# Transforming in a dict (same as result above)\n",
    "model_data = json.load(f)\n",
    "model_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we have the JSON file, you only need to implement the prediction of the StandardScaler method in any language your desire (the formular can be found in [Wikipedia](https://en.wikipedia.org/wiki/Standard_score)). For example, in python it is easy to implement the standard-scaler using numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-20T17:27:06.881905Z",
     "start_time": "2021-04-20T17:27:06.876235Z"
    }
   },
   "outputs": [],
   "source": [
    "# An example of a standard scalar implemented with model_data\n",
    "def standard_scaler(X, model_data):\n",
    "    mean = np.asarray(model_data['mean'])\n",
    "    std = np.asarray(model_data['std'])\n",
    "    Xz = (X-mean)/std\n",
    "    return Xz\n",
    "\n",
    "# Same as Xz\n",
    "Xz_pred = standard_scaler(X, model_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also possible to store simpler versions of the StandardScaler as the \"MeanScaler\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-20T17:27:07.286976Z",
     "start_time": "2021-04-20T17:27:07.273819Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'scaler': 'MeanScaler',\n",
       " 'mean': [5.843333333333335,\n",
       "  3.057333333333334,\n",
       "  3.7580000000000027,\n",
       "  1.199333333333334]}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removing mean of features\n",
    "scaler = StandardScaler(with_std=False)\n",
    "Xz = scaler.fit_transform(X)\n",
    "\n",
    "# Exporting again\n",
    "export = Export(scaler)\n",
    "export.to_json(filename='mean_scaler.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or the \"StandardDeviationScaler\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-20T17:27:07.655690Z",
     "start_time": "2021-04-20T17:27:07.644658Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'scaler': 'StandardDeviationScaler',\n",
       " 'std': [0.8253012917851409,\n",
       "  0.43441096773549437,\n",
       "  1.7594040657753032,\n",
       "  0.7596926279021594]}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removing mean of features\n",
    "scaler = StandardScaler(with_mean=False)\n",
    "Xz = scaler.fit_transform(X)\n",
    "\n",
    "# Exporting again\n",
    "export = Export(scaler)\n",
    "export.to_json(filename='std_scaler.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exporting MinMaxScaler\n",
    "\n",
    "Another common technique to normalize data is MinMaxScaler. It normalize data to be in the interval $[\\text{lower},\\text{upper}]$. It is in the package `sklearn.preprocessing`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-20T17:27:08.025263Z",
     "start_time": "2021-04-20T17:27:08.020916Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us normalize the features of the iris dataset and save it using `sklearn-export`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-20T17:27:08.397739Z",
     "start_time": "2021-04-20T17:27:08.388187Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lower': 0,\n",
       " 'upper': 1,\n",
       " 'min': [4.3, 2.0, 1.0, 0.1],\n",
       " 'max': [7.9, 4.4, 6.9, 2.5],\n",
       " 'scaler': 'MinMaxScaler'}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalizing data to be in the interval [lower, upper]\n",
    "scaler = MinMaxScaler()\n",
    "Xz = scaler.fit_transform(X)\n",
    "\n",
    "# Exporting again\n",
    "export = Export(scaler)\n",
    "export.to_json(filename='minmax_scaler.json')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
